{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBABILITY_THRESHOLD = .5\n",
    "\n",
    "\n",
    "class PositiveUnlabeledClassifier:\n",
    "    def __init__(self, calibration_share=.4, svm_reg=.1):\n",
    "        self.svm = None\n",
    "        self.platt_scaler = None\n",
    "        self.c = None\n",
    "        self.calibration_share = calibration_share\n",
    "        self.svm_reg = svm_reg\n",
    "        \n",
    "    def fit(self, x_train, s_train, x_val, s_val):\n",
    "        x_train_svm, x_train_calibration, s_train_svm, s_train_calibration = \\\n",
    "            train_test_split(x_train, s_train, train_size=1 - self.calibration_share)\n",
    "        class_weight = {i: np.mean(s_train_svm != i) for i in np.unique(s_train_svm)}\n",
    "        self.svm = SVC(C=1 / self.svm_reg, class_weight=class_weight).fit(x_train_svm, s_train_svm)\n",
    "        \n",
    "        svm_df_calibration = self.svm.decision_function(x_train_calibration).reshape(-1, 1)\n",
    "        self.platt_scaler = LogisticRegression().fit(svm_df_calibration, s_train_calibration)\n",
    "        \n",
    "        val_s_proba = self._predict_s_proba(x_val)\n",
    "        self.c = val_s_proba[s_val > 0].mean()\n",
    "    \n",
    "    def _predict_s_proba(self, x):\n",
    "        svm_df = self.svm.decision_function(x).reshape(-1, 1)\n",
    "        return self.platt_scaler.predict_proba(svm_df)[:, 1]\n",
    "    \n",
    "    def predict_proba(self, x):\n",
    "        return self._predict_s_proba(x) / self.c\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.predict_proba(x) > PROBABILITY_THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_x, mnist_y = fetch_openml('mnist_784', return_X_y=True)\n",
    "mnist_y = np.int32(mnist_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_minst_mask = mnist_y < 2\n",
    "bin_mnist_x, bin_mnist_y = mnist_x[bin_minst_mask], mnist_y[bin_minst_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_C = .25\n",
    "\n",
    "\n",
    "s_mask = np.random.binomial(1, REAL_C, bin_mnist_y.shape)\n",
    "bin_mnist_s = bin_mnist_y * s_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: c=0.2673770716327467 F1=0.9726071543667418\n",
      "Fold 2: c=0.25218167150465876 F1=0.9753886010362693\n",
      "Fold 3: c=0.24541346798156993 F1=0.9774011299435028\n",
      "Fold 4: c=0.24521687262780292 F1=0.975\n",
      "Fold 5: c=0.23959627773903044 F1=0.9640780020526856\n",
      "5-fold average c: 0.24995707229716174, average F1: 0.97289497747984\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 5\n",
    "\n",
    "\n",
    "folds = np.random.randint(N_FOLDS, size=bin_mnist_y.shape)\n",
    "cs, f1s = [], []\n",
    "for index_test in range(N_FOLDS):\n",
    "    index_val = (index_test + 1) % N_FOLDS\n",
    "    val_mask = folds == index_val\n",
    "    test_mask = folds == index_test\n",
    "    train_mask = ~(val_mask | test_mask)\n",
    "    \n",
    "    x_train = bin_mnist_x[train_mask]\n",
    "    x_val = bin_mnist_x[val_mask]\n",
    "    x_test = bin_mnist_x[test_mask]\n",
    "    \n",
    "    s_train = bin_mnist_s[train_mask]\n",
    "    s_val = bin_mnist_s[val_mask]\n",
    "    \n",
    "    y_test = bin_mnist_y[test_mask]\n",
    "    \n",
    "    pul = PositiveUnlabeledClassifier()\n",
    "    pul.fit(x_train, s_train, x_val, s_val)\n",
    "    \n",
    "    cs.append(pul.c)\n",
    "    f1 = f1_score(y_test, pul.predict(x_test))\n",
    "    f1s.append(f1)\n",
    "    print(f'Fold {index_test + 1}: c={pul.c} F1={f1}')\n",
    "    \n",
    "print(f'{N_FOLDS}-fold average c: {np.mean(cs)}, average F1: {np.mean(f1s)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
